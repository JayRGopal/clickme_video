
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Style stuff and title -->
    <title>CLICKTIONARY</title>
    <link rel="icon" href="web_content/favicon.ico">

    <!-- Bootstrap core CSS -->
    <link href="../node_modules/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../style/cover.css" rel="stylesheet">
    <link href="../style/signin.css" rel="stylesheet">
    <script type="text/javascript" src="../script/jquery-1.11.2.js"></script>
    <script type="text/javascript">
      $(function(){
        $('#btnSignIn').click(function(evt){
          evt.preventDefault();

          $.ajax({
            url: '/signin',
            type:'POST',
            success:function(response){
              console.log(response);
            },
            error:function(error){
              console.log(error);
            }
          })

        })
      })

     
    </script>

  </head>

  <body>

    <div class="site-wrapper">

      <div class="site-wrapper-inner">

        <div class="cover-container">

          <div class="masthead clearfix">
            <div class="inner">
              <nav>
                <ul class="nav masthead-nav">
                  <li><a href="/">Home</a></li>
                  <li class="active"><a href="#">What's the point?</a></li>
                </ul>
              </nav>
            </div>
          </div>
          <br>
          <br>
          <br>
          <div class="inner cover">
            <h1 class="cover-heading">CLICKTIONARY</h1>
            <p><em>A web-based application for exploring the atoms of object recognition.</em></p>
            <br>
            <p style="text-align:left">Advances in AI have allowed computers to begin to see the world like humans. In fact, many of the services we use in our daily lives take advantage of these rapid developments, including facebook, google image search, and self-driving cars. However, we have found that there are neverless still major differences between man and machine:
            <br>
            <p style="text-align:center"><img src="/web_content/realization_example.png" height=120 width=280></p>
            <p><b>Modern AI systems recognize objects with different visual features than Humans.</b></p>
            <p style="text-align:left">For example, in the figure above  we find that when recongizing glasses, leading AIs for computer vision such as the one featured on this website are strongly influenced by the glass lenses. In contrast, recognition for humans is typically based on the glasses frames. We find this difference is systematic, which opens up opportunities to build more human-like AI.<br></p>
            <b>CLICKTIONARY is a game that will provide us with data to drive AI towards human-like recognition.</b>
            <br><br>
            <p style="text-align:left">Every time you play CLICKTIONARY, you provide us with valuable data about the parts of animals and objects that Humans use for recognition. We use this data in the following ways:</p>
            <li style="text-align:left">First, to train AIs that will predict these feature locations in any image.</li><li style="text-align:left">Second, to use these predictions to train AIs for more human-like recognition, which we find improves classification accuracy.</li></p><b>See below for real-time results on the impact of these maps on DCN recognition. For more details on the project motivating this application, please visit our [<a href="http://___.edu/">arxiv</a>], currently under review for CVPR 2017.</b>
            <hr>
            <div class="inner cover">
              <h1 class="cover-heading">Real-time results</h1>
              <p>Here we record VGG 16 accuracy on ImageNet Top-1 object classification after modulating its activity with a model that predicts Human realization maps. These realization maps are predicted based on where people click in images on the main page.
              <br><br>
              <canvas id="myChart" width="500" height="200"></canvas>
            </div>
          </div>
            <div class="inner">
              <p>[by <a href="http://___.edu/"> HAL</a>]</p>
            </div>
        </div>
      </div>
    </div>

    <!-- Footer script -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.1.4/Chart.min.js"></script>
    <script src="../script/about.js" type="text/javascript"></script>
  </body>
</html>
